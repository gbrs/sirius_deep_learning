{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18ZPGjBVBwu2"
   },
   "source": [
    "Код составлен на основе туторила с Kaggle: [ссылка](https://www.kaggle.com/code/neerajmohan/fine-tuning-bert-for-text-classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUfWhhv3Cf0V",
    "outputId": "0402b8c2-4443-474a-97a3-f17c05bdb1b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuNgRj0zDTz8"
   },
   "source": [
    "# Обучение BERT для классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BroWdIiDk3m"
   },
   "source": [
    "Задача: создать модель, которая по тексту сообщения будет определять, говорится в нем о катастрофе (например пожаре) или нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ah82CHT5Pu9h"
   },
   "source": [
    "## Подгрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UldXD59WBu0b",
    "outputId": "4d8b5cef-f79b-4ee2-dd94-9457b63c6835"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertTokenizer, get_linear_schedule_with_warmup\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNbRJAR0Cd_-",
    "outputId": "982f870c-771a-4b18-e172-b61d37259f61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ptfN_RVDCotv",
    "outputId": "a6fc19fe-9cf6-4b99-ae1b-27ef4bddd069"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d2624f59-921d-4f46-892d-a2e1fb494f89\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2624f59-921d-4f46-892d-a2e1fb494f89')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d2624f59-921d-4f46-892d-a2e1fb494f89 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d2624f59-921d-4f46-892d-a2e1fb494f89');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-7eaa260b-7fbf-4c87-923a-af1c1a8fa236\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7eaa260b-7fbf-4c87-923a-af1c1a8fa236')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-7eaa260b-7fbf-4c87-923a-af1c1a8fa236 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"/content/Text classification train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UFB8bBASDDi2"
   },
   "outputs": [],
   "source": [
    "sw = stopwords.words('english') # Список слов, которые не помогут нам при классификации\n",
    "#['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves' ... ]\n",
    "\n",
    "# Функция для очистки текста\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n",
    "    text = re.sub(r\"http\\S+\", \"\",text)\n",
    "    text = re.sub(r\"http\", \"\",text)\n",
    "    html=re.compile(r'<.*?>')\n",
    "\n",
    "    text = html.sub(r'',text)\n",
    "\n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'')\n",
    "\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l-lQS9rAEs22"
   },
   "outputs": [],
   "source": [
    "# Очищаем данные\n",
    "train_data['text'] = train_data['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LEbHmuPxFPcI"
   },
   "outputs": [],
   "source": [
    "X = train_data.text.values\n",
    "y = train_data.target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Pc0UMuWFZLW"
   },
   "source": [
    "Вызовем токенизатор из библиотеки transformers. Он будет обучен уже на основе указанного типа - bert-base-uncased. Тип обозначает, что мы будем использовать стандартный BERT из статьи(например, можно указать вместо него RoBERTa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5E0_m8wFFUw3"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dudEdU35GCTJ",
    "outputId": "167980b3-9354-4de1-f57f-93d26438670b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходная последовательность:  forest fire near la ronge sask canada\n",
      "Токенизация:  ['forest', 'fire', 'near', 'la', 'ron', '##ge', 'sas', '##k', 'canada']\n",
      "ID токенов:  [15616, 3114, 8372, 2089, 16455, 9641, 2149]\n"
     ]
    }
   ],
   "source": [
    "print('Исходная последовательность: ', X[1])\n",
    "print('Токенизация: ', tokenizer.tokenize(X[1]))\n",
    "print('ID токенов: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(X[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WU4pPf7NGLT7",
    "outputId": "89fe4fd0-a768-42cf-bc34-ac4cca53ec43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длина предложения:  45\n"
     ]
    }
   ],
   "source": [
    "# Рассчитаем максимальную длину предложения\n",
    "max_len = 0\n",
    "\n",
    "for sent in X:\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Максимальная длина предложения: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OD0CoHZIwYT",
    "outputId": "0bfec89e-fef9-42a8-ef88-24cf0915692a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходная последовательность:  forest fire near la ronge sask canada\n",
      "\n",
      "Токены: tensor([  101,  3224,  2543,  2379,  2474,  6902,  3351, 21871,  2243,  2710,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0])\n",
      "\n",
      "Маска: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "padding_masks = []\n",
    "\n",
    "for sequence in X:\n",
    "    # `encode_plus` состоит из следующих этапов:\n",
    "    #   (1) Разделяем на слова.\n",
    "    #   (2) Добавляем `[CLS]` токен в начале.\n",
    "    #   (3) Добавляем `[SEP]` токен в конце.\n",
    "    #   (4) Токенизируем.\n",
    "    #   (5) Обрезаем до max_len и добавляем padding.\n",
    "    #   (6) Получаем padding_mask для `[PAD]` токенов.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sequence,\n",
    "                        add_special_tokens = True, # добавляем '[CLS]' и '[SEP]'\n",
    "                        max_length = max_len,      # указываем макс. длину\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # создаем маску внимания для pad\n",
    "                        return_tensors = 'pt',     # возвращаем тензор\n",
    "                   )\n",
    "\n",
    "    # Добавляем токенезированную последовательность в датасет\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # Добавляем максу внимания для tokens\n",
    "    padding_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Преобразуем датасет в формат torch\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "padding_masks = torch.cat(padding_masks, dim=0)\n",
    "y = torch.tensor(y)\n",
    "# Вывдем результаты\n",
    "print('Исходная последовательность: ', X[1])\n",
    "print(\"\")\n",
    "print('Токены:', input_ids[1])\n",
    "print(\"\")\n",
    "print('Маска:', padding_masks[1])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41VvU2j5LpZ5",
    "outputId": "9ca9ceae-7690-4047-f53c-2cb6647ffc9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,090 обучающих последовательностей\n",
      "1,523 валидационных последовательностей\n"
     ]
    }
   ],
   "source": [
    "# Создаем класс датасета\n",
    "dataset = TensorDataset(input_ids, padding_masks, y)\n",
    "\n",
    "# Разделяем данные на обучающую и валидационную выборки\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset)  - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} обучающих последовательностей'.format(train_size))\n",
    "print('{:>5,} валидационных последовательностей'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Y5yg8yRLNJsY"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXLAdGpNP2Fz"
   },
   "source": [
    "## Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFYZQu50NePT",
    "outputId": "70c898a4-06f9-4d5e-9e39-c10454bed718"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",  # Указываем такой же тип как в токенизаторе (классический берт).\n",
    "    num_labels = 2,  # Количество классов.\n",
    "    output_attentions = False,  # Можно получать на выходе ещё резульататы внимания, но нам это не надо.\n",
    "    output_hidden_states = False,  # Можно получать все выходы на слоях, но это тоже не нужно.\n",
    ")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYIjW33WN7PX",
    "outputId": "ba00adbb-a43c-4b81-be2b-7055cb4df173"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-Vs2ENRP9yO"
   },
   "source": [
    "## Обучающий цикл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIN1AQhDQKEO",
    "outputId": "25ec0150-7e07-412f-917e-dd87e1a14742"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ExridDHXQA5A"
   },
   "outputs": [],
   "source": [
    "# Авторы BERT рекомендуют использовать 2-4 эпохи, иначе есть риск переобучиться.\n",
    "epochs = 4\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Lr scheduler изменяет lr на основе batch или epoch.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Teh_OVaQn5k"
   },
   "source": [
    "### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nJC_O8RDN-vY"
   },
   "outputs": [],
   "source": [
    "# Функция для измерения качества\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "i7n71YVMQj38"
   },
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mrkbb3Vd9LiU"
   },
   "source": [
    "### Запускаем обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pvYl4SxNQmi_",
    "outputId": "7bbed1b4-1f59-47a1-9210-5af17d503823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Обучение...\n",
      "\n",
      "  Средний loss обучающей выборки: 0.29\n",
      "  Время, затраченное на эпоху: 0:00:51\n",
      "\n",
      "Валдиация модели...\n",
      "  Accuracy: 0.83\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Обучение...\n",
      "\n",
      "  Средний loss обучающей выборки: 0.30\n",
      "  Время, затраченное на эпоху: 0:00:50\n",
      "\n",
      "Валдиация модели...\n",
      "  Accuracy: 0.82\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Обучение...\n",
      "\n",
      "  Средний loss обучающей выборки: 0.24\n",
      "  Время, затраченное на эпоху: 0:00:50\n",
      "\n",
      "Валдиация модели...\n",
      "  Accuracy: 0.83\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Обучение...\n",
      "\n",
      "  Средний loss обучающей выборки: 0.22\n",
      "  Время, затраченное на эпоху: 0:00:50\n",
      "\n",
      "Валдиация модели...\n",
      "  Accuracy: 0.83\n",
      "\n",
      "Обучение завершено!\n",
      "Всего было затрачено 0:03:43 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Обучение...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_X = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_y = batch[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(b_X,\n",
    "                       token_type_ids=None,\n",
    "                       attention_mask=b_input_mask, # BERT требует на вход padding_mask\n",
    "                       labels=b_y)\n",
    "\n",
    "        loss = output.loss\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Ограничиваем значения градиентов максимальным значением 1\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Считаем средний loss для данной epoch\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Измеряем затраченное время\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Средний loss обучающей выборки: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Время, затраченное на эпоху: {:}\".format(training_time))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Валдиация модели...\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        b_X = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_y = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output= model(b_X,\n",
    "                          token_type_ids=None,\n",
    "                          attention_mask=b_input_mask,\n",
    "                          labels=b_y)\n",
    "        loss = output.loss\n",
    "        total_eval_loss += loss.item()\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_y.to('cpu').numpy()\n",
    "        # сохраняем качество\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Измеряем среднее качество\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Измеряем время валидации.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    if avg_val_accuracy > best_eval_accuracy:\n",
    "        torch.save(model, 'bert_model')\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "\n",
    "    # Записываем все статистики для эпохи.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Обучение завершено!\")\n",
    "\n",
    "print(\"Всего было затрачено {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Kt8g-R5QArMc",
    "outputId": "7f4d2fd2-4418-4088-a2de-fde5513e3174"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'omg, saw fire forest'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequnece = \"Omg, I just saw a fire in the forest!\"\n",
    "input_sequnece = clean_text(input_sequnece)\n",
    "input_sequnece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fzTaLcS8RU6",
    "outputId": "6df99df4-3d40-4ba8-b6fb-4896930a9112"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 18168,  2290,  1010,  2387,  2543,  3224,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict = tokenizer.encode_plus(\n",
    "                        input_sequnece,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = max_len,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "encoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "GOFIkOjVCIVh"
   },
   "outputs": [],
   "source": [
    "b_X = encoded_dict['input_ids']\n",
    "padding_mask = encoded_dict['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGAmpuFRB5cp",
    "outputId": "5f09b48b-bff4-401a-93e4-debf80cc566c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "b_X = b_X.to(device)\n",
    "padding_mask = padding_mask.to(device)\n",
    "pred = np.argmax(model(b_X, attention_mask=padding_mask)['logits'].detach().cpu())\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
